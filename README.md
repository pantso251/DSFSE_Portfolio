# Data Science for Smart Environments - Individual Portfolio
**Panagiotis Tsoutsouris**

## Background and Motivation

Having an academic background in Environmental Systems Management with a focus on precision agriculture and my current MSc in Geo Information Science has helped me develop a strong spatial way of thinking, allowing me to approach environmental questions increasingly from a "where" perspective, whether the focus is on forests, fields or coastal areas. 

In my studies I have frequently used Python's geospatial libraries (such as GeoPandas and rasterio), and I am currently working with the lidR package in R for my thesis, further strengthening my knowledge in handling spatial data. During last academic year's ACT course in period 6, I developed a concise Google Earth Engine script, an ML workflow and GitHub integration for collaborating with my team, which introduced me to reproducible geospatial analysis and required me to explain results to a real life commissioning agent.

In most earlier courses, however, data were provided in relatively clean form, especially in the case of remote sensing products, and only limited noise correction or preprocessing was needed. **In this course I wanted to delve into finding, assessing and cleaning my own data from different sources, instead of relying on pre-packaged datasets.** What I found most exhilarating in this course was developing a web scraping application, which enabled me to tell a story of protecting the environment in a new data-driven way.

---

## Project Context: Beach Pollution Analysis in Italy

This portfolio documents my individual learning journey within a collaborative group project analyzing **beach pollution and quality in Italy** using smart environment data sources. The project combined Google Places API data (ratings, reviews, keyword analysis) with geospatial analysis to create interactive visualizations for policymakers and students.

---

## SMART Learning Goals

### üéØ [Goal 1: Finding Suitable Data Sources](learning-goals/goal-1-data-sources/)
**Category:** Data acquisition, wrangling, storing

**Goal:** Within this course, I want to independently identify and locate suitable environment-related data sources for our group project. Following that, proper storing and processing will take place through a git version control system.

**How:** Selected sources will be stored in the team's database and all processing followed will be documented in `.ipynb` scripts with strong and supportive comments and notations.

---

### üéØ [Goal 2: Web Scraping and Cleaning](learning-goals/goal-2-web-scraping/)
**Category:** Data acquisition, wrangling, storing

**Goal:** I want to be able to develop a small web scraping workflow in Python that extracts selected indicators (photos, reviews, hashtags) and exports them into a table accessible with scripting. The latter should then be directly linked to our main data source.

**How:** An `.ipynb` that shows scraping (or API use) of web sources, cleaning steps and a merged, analysis-ready table.

---

### üéØ [Goal 3: Providing Clear, Story-Driven Results](learning-goals/goal-3-visualization/)
**Category:** Information combining, analysis, communication

**Goal:** By the end of the course, I want to be able to turn the combined dataset into a small set of key results (plots/maps) that clearly tell a story about the environment and beach pollution, and to explain these results through interactive thematic maps (choropleth, folium) in an accessible way for a less informed audience such as Italian policy makers or students.

**How:** I will select 2‚Äì3 key figures (such as plots or maps) and write a short, informative explanation of the main findings and their limitations aimed at non-experts (e.g. Italian policy makers or students) and include this text and the figures in my portfolio.

---

### üéØ [Goal 4: Brief Mentoring of a Less Experienced Teammate](learning-goals/goal-4-mentoring/)
**Category:** Knowledge quality, communication, social aspects

**Goal:** During the project, I want to support our less data-acquainted team member in understanding and executing specific technical steps (e.g. basic cleaning or basic mapping). By doing this I will help our team not fall behind or lack understanding of the workflow.

**How:** Creating reproducible steps together with clear documentation of choices and scripting as well as providing guidance throughout the project when advised.

---

## Portfolio Structure
**How to Navigate This Portfolio:**
Start with [REFLECTION.md](REFLECTION.md) for an overview of my learning journey, then explore individual [learning goals](learning-goals/) for detailed documentation of each objective.

Each learning goal has its own dedicated folder containing:
- **Background** - Context and motivation
- **Methodology** - Approach and data sources used
- **Implementation** - Notebooks, code, and technical details
- **Results** - Outputs and findings
- **Conclusions** - Reflection on both results and goal accomplishment

---

## Reflection

For a comprehensive reflection on my learning process, including Boundary Crossing Competence (BCC) examples, what went well and what didn't, and societal implications of smart technologies, see [REFLECTION.md](REFLECTION.md).

---

## Repository Navigation

- üìÅ [`learning-goals/`](learning-goals/) - Detailed documentation for each of the 4 SMART goals
- üìÅ [`notes/`](notes/) - Learning notes and documentation (not yet available)
- üìÅ [`projects/`](projects/) - Project-related materials (opens to different public repo of group project)
- üìÅ [`weekly-reflections/`](weekly-reflections/) - Personal reflections from week 1 to 3
- üìÑ [REFLECTION.md](REFLECTION.md) - BCC, societal implications reflection and a final reflection of the course

---

**Course:** GRS53509 Data Science For Smart Environments  
**Institution:** Wageningen University & Research  
**Date:** January 2026
